{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "RG3sRuu7DzY0"
      },
      "source": [
        "Data Preparation\n",
        "* Data loading from data_train.json\n",
        "* Basic features(user type, application time) processing and exploration\n",
        " * Application time ---- processed into day of week, time of the day.\n",
        " * Check the relationship between fraud and user type/appication time\n",
        "* Sequential User behavior features processing and exploration\n",
        " * stay time, lag time between pages, time span of an application, page transitions overview.\n",
        "* Processing data for model building\n",
        " * Sequential data padding\n",
        " * Standardization\n",
        " * Save in json format\n",
        "* Generate Markov Transition Field along features. \n",
        " * Zhang, R., Zheng, F., & Min, W. (2018). Sequential Behavioral Data Processing Using Deep Learning and the Markov Transition Field in Online Fraud Detection. arXiv preprint arXiv:1808.05329.\n",
        " * All features are bin and one-hot encoded into a binary vector.\n",
        " * matrix[i,j]  represents the probability that j=1 given i=1\n",
        "* Generate Markov Transition Field along timesteps and Gramian Angular Field(code only)\n",
        " * Wang, Z., & Oates, T. (2015, April). Encoding time series as images for visual inspection and classification using tiled convolutional neural networks. In Workshops at the Twenty-Ninth AAAI Conference on Artificial Intelligence."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-04-28T04:27:17.508554Z",
          "start_time": "2020-04-28T04:27:17.503568Z"
        },
        "colab": {},
        "colab_type": "code",
        "id": "QwwXGSE5DzZK"
      },
      "outputs": [],
      "source": [
        "from datetime import datetime\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import json\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy import stats\n",
        "from gensim.models import Word2Vec\n",
        "from sklearn.manifold import TSNE\n",
        "import os\n",
        "import pickle\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 778
        },
        "colab_type": "code",
        "executionInfo": {
          "elapsed": 1426,
          "status": "error",
          "timestamp": 1590035296307,
          "user": {
            "displayName": "Hanyu Wu",
            "photoUrl": "",
            "userId": "05588030028148674891"
          },
          "user_tz": -480
        },
        "id": "oXnbVSq4XiU-",
        "outputId": "506a8828-d113-417a-bfda-bce5a1978167"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "os.chdir(\"drive/My Drive/Online Lending/Sequential Embedding/Spring 2020/low_income_data\") \n",
        "# os.chdir(\"\") # give the path to the data file.\n",
        "os.listdir()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "34vLSQwQXmSS"
      },
      "outputs": [],
      "source": [
        "data_dir = 'processed/'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "4FKluv7lDzaj"
      },
      "source": [
        "# Data loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-04-28T03:30:39.204790Z",
          "start_time": "2020-04-28T03:30:39.202799Z"
        },
        "colab": {},
        "colab_type": "code",
        "id": "0eiwURUjTfgW"
      },
      "outputs": [],
      "source": [
        "# change to raw data folder\n",
        "# os.chdir(os.path.abspath(os.path.join(data_dir, \"../../data/raw\")))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-04-28T03:30:53.959549Z",
          "start_time": "2020-04-28T03:30:39.205767Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "colab_type": "code",
        "executionInfo": {
          "elapsed": 3073,
          "status": "ok",
          "timestamp": 1590033968517,
          "user": {
            "displayName": "Hanyu Wu",
            "photoUrl": "",
            "userId": "05588030028148674891"
          },
          "user_tz": -480
        },
        "id": "nzGeQjCDDza8",
        "outputId": "72775cad-e467-4cea-cd97-57f11d145e3a",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: user 1.49 s, sys: 420 ms, total: 1.91 s\n",
            "Wall time: 2.72 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "sequential_data = []\n",
        "\n",
        "line_number = 0\n",
        "max_lines = 100\n",
        "# with open('raw/data_train.json', 'r') as f:\n",
        "with open('raw/test_new.json', 'r') as f:\n",
        "    for line in f:\n",
        "#         if len(sequential_data) > max_lines:\n",
        "#             break\n",
        "        sequential_data.append(json.loads(line))\n",
        "# sequential_data = sequential_data[:100]\n",
        "len(sequential_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-04-28T03:30:56.127858Z",
          "start_time": "2020-04-28T03:30:53.960517Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "colab_type": "code",
        "executionInfo": {
          "elapsed": 525,
          "status": "ok",
          "timestamp": 1590033978017,
          "user": {
            "displayName": "Hanyu Wu",
            "photoUrl": "",
            "userId": "05588030028148674891"
          },
          "user_tz": -480
        },
        "id": "coI759MXDzb0",
        "outputId": "c27832cb-9510-47a9-8c46-01403cc89012"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(30672, 30672)"
            ]
          },
          "execution_count": 9,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sequential_driver = {}\n",
        "\n",
        "sequential_behavior = {}\n",
        "\n",
        "for item in sequential_data:\n",
        "    user_id = item[0]\n",
        "    application_time = int(item[1]['order_info']['order_time'])\n",
        "    sequential_driver.update({f\"{user_id}|{application_time}\": item[1]['order_info']})\n",
        "    sub_data = [x for x in item[1]['data']\n",
        "                if x['petime'] <= application_time-100]\n",
        "    # we only keep data occurs before application time. \"-100\" is not neccessary for offline data cleaning.\n",
        "    # but sometimes we use this trick for online calculation to avoid network slowdown\n",
        "    sequential_behavior.update({f\"{user_id}|{application_time}\": sub_data})\n",
        "## driver saved user data, while behavior saved both user data and behavior sequence\n",
        "len(sequential_behavior), len(sequential_driver)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "KiE148qbDzgp"
      },
      "source": [
        "# Preprocessing data for model building"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "colab_type": "code",
        "executionInfo": {
          "elapsed": 361,
          "status": "ok",
          "timestamp": 1590035325103,
          "user": {
            "displayName": "Hanyu Wu",
            "photoUrl": "",
            "userId": "05588030028148674891"
          },
          "user_tz": -480
        },
        "id": "CQBHQd3MTfgd",
        "outputId": "c9409a6e-a3f7-4750-e5c0-b262ec61431b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['0ed9672fa61f4d6da241a6289000e2f2|1507102200000',\n",
              " '48b72ca5b43248d3b50dfadb76c651a2|1508810700000',\n",
              " '8e669f481a4645c89de0f29f980522e9|1508354520000',\n",
              " 'd9a86017a67140ab96d9c405d1ebb02d|1507129920000',\n",
              " '96e3ded73e6b47ba91108e5b6a923c81|1509348180000',\n",
              " '593c8f76b5164c08a52c7fc1bf99d283|1508970600000',\n",
              " 'e87ffe735fba4541a009967d25b0e714|1507058160000',\n",
              " '8e6c5ba3d14c41539b64816c4692f142|1507671840000',\n",
              " '3f8e1ae4c91147138fbdc5ea8aa17302|1508903820000',\n",
              " 'ed76629b471b4496ab9b979eda237c20|1508883240000']"
            ]
          },
          "execution_count": 38,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "unique_user_session = list(set(sequential_behavior.keys()))\n",
        "keys_order = list()\n",
        "for i in sequential_behavior.keys():\n",
        "    if sequential_behavior[i] !=[]:\n",
        "        keys_order.append(i)\n",
        "keys_order[:10]\n",
        "# len(keys_order)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "lZS9Ojb1Tfgf"
      },
      "source": [
        "## Processing Data for Word2vec Embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-04-28T03:33:57.124005Z",
          "start_time": "2020-04-28T03:33:55.800542Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "colab_type": "code",
        "executionInfo": {
          "elapsed": 1868,
          "status": "ok",
          "timestamp": 1590033983362,
          "user": {
            "displayName": "Hanyu Wu",
            "photoUrl": "",
            "userId": "05588030028148674891"
          },
          "user_tz": -480
        },
        "id": "kEsybNJUTfgg",
        "outputId": "c4364104-b02c-465a-9a48-df4e1d705f6c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "some information about the the data shape to help you undestand the data:\n",
            "number of users: 19617\n",
            "timestamps length of behaviors of the first user: 15\n",
            "timestamps length of behaviors of the second user: 21\n",
            "Different user may have different page viewing sequence length(i.e. timestaps length), but we later decide to modify all to 60 timestamps\n"
          ]
        }
      ],
      "source": [
        "# This is for word2vec embedding. In this part, we will not do one hot endoing for page types.\n",
        "def data_process_for_embedding(sequence_for_a_single_application):\n",
        "    '''\n",
        "    Function to process signle application\n",
        "    '''\n",
        "    sequence_for_a_single_application.sort(key=lambda x: x['petime'])\n",
        "    page_sequence = [x['pname'] for x in sequence_for_a_single_application]\n",
        "    pstart = [x['pstime'] for x in sequence_for_a_single_application]\n",
        "    pend = ([x['petime'] for x in sequence_for_a_single_application])\n",
        "\n",
        "#     mark some outliers as -1 and  take the logarithm of the lag time.\n",
        "    page_stay_time = [np.log((y-x)/1000 +1) if (y-x)>0 and (y-x)//1000<800 else -1 for x,y in zip(pstart, pend)]\n",
        "#     mark some outliers as -1 and  take the logarithm of the lag time.\n",
        "#     page_lagg_time = [np.log((x-y)/1000 +1)if (x-y)>=0  else -1 for x,y in zip(pstart[1:], pend[:-1])]\n",
        "\n",
        "#     page_lagg_time_padd=[0]\n",
        "#     page_lagg_time_padd.extend(page_lagg_time)\n",
        "\n",
        "    return page_sequence  ,page_stay_time #,page_lagg_time_padd\n",
        "\n",
        "\n",
        "def get_data_for_embedding(x):\n",
        "    sequence_data = []\n",
        "    stay_time_sequence = list()\n",
        "    overdue = []\n",
        "    for keys in keys_order:\n",
        "        #page_sequence, page_stay_time, page_lagg_time = data_process_for_embedding(x[keys])\n",
        "        page_sequence, stay_time = data_process_for_embedding(x[keys])\n",
        "        # single_entry=np.vstack((page_sequence, page_stay_time, page_lagg_time)).T\n",
        "        sequence_data.append(page_sequence)\n",
        "        stay_time_sequence.append(stay_time)\n",
        "    return sequence_data, stay_time_sequence\n",
        "\n",
        "\n",
        "sequence_data_for_embedding, sequence_stay_time = get_data_for_embedding(sequential_behavior)\n",
        "# sequence_data_for_embedding=np.array(sequence_data_for_embedding)\n",
        "# sequence_data_for_embedding.shape\n",
        "print(\"some information about the the data shape to help you undestand the data:\")\n",
        "print(f\"number of users: {len(sequence_data_for_embedding)}\")\n",
        "print(\n",
        "    f\"timestamps length of behaviors of the first user: {len(sequence_data_for_embedding[0])}\")\n",
        "print(\n",
        "    f\"timestamps length of behaviors of the second user: {len(sequence_data_for_embedding[1])}\")\n",
        "print(\"Different user may have different page viewing sequence length(i.e. timestaps length), but we later decide to modify all to 60 timestamps\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-04-28T03:34:01.705790Z",
          "start_time": "2020-04-28T03:33:57.125002Z"
        },
        "colab": {},
        "colab_type": "code",
        "id": "ckjlDQE4Tfgi"
      },
      "outputs": [],
      "source": [
        "# This is to train our own word2vec model. NB: we do not use pre-trained word2vec model!\n",
        "model = Word2Vec(sequence_data_for_embedding, min_count=1,\n",
        "                 size=50, workers=3, window=5, sg=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-04-28T03:34:08.188431Z",
          "start_time": "2020-04-28T03:34:01.708779Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "colab_type": "code",
        "executionInfo": {
          "elapsed": 1738,
          "status": "ok",
          "timestamp": 1590033989542,
          "user": {
            "displayName": "Hanyu Wu",
            "photoUrl": "",
            "userId": "05588030028148674891"
          },
          "user_tz": -480
        },
        "id": "a3P_LgLLTfgk",
        "outputId": "f2dcbadb-9804-428d-fa2c-7c72ec219322"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "number of users: 19617\n",
            "number of behaviors of first user: 15\n",
            "number of behaviors of second user: 21\n",
            "embedding size of every page type: 50\n",
            "the shape of sequence_data_embedded is (19617,X,50) where X is the number of behaviors of each user, it is not a fixed number\n"
          ]
        }
      ],
      "source": [
        "# After word2vec, let's see what the data strcture looks like. \n",
        "# The change is that, now every page type has been modified into a vector of length 50\n",
        "# (this vector length can be changed, it is a hymperparameter of word2vec model).\n",
        "sequence_data_embedded = []\n",
        "for i in range(len(sequence_data_for_embedding)):\n",
        "    sequence_data_embedded_for_a_single_user = []\n",
        "    for j in range(len(sequence_data_for_embedding[i])):\n",
        "        sequence_data_embedded_for_a_single_user.append(model.wv[sequence_data_for_embedding[i][j]])\n",
        "    sequence_data_embedded.append(sequence_data_embedded_for_a_single_user)\n",
        "print(f\"number of users: {len(sequence_data_embedded)}\")\n",
        "print(f\"number of behaviors of first user: {len(sequence_data_embedded[0])}\")\n",
        "print(f\"number of behaviors of second user: {len(sequence_data_embedded[1])}\")\n",
        "print(f\"embedding size of every page type: {len(sequence_data_embedded[0][0])}\")\n",
        "print(\"the shape of sequence_data_embedded is (19617,X,50) where X is the number of behaviors of each user, it is not a fixed number\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "zHW60eaiDzhF"
      },
      "source": [
        "## Pad the sequence into the same length"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-04-28T03:34:16.130893Z",
          "start_time": "2020-04-28T03:34:14.957907Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "colab_type": "code",
        "executionInfo": {
          "elapsed": 445,
          "status": "ok",
          "timestamp": 1590034015189,
          "user": {
            "displayName": "Hanyu Wu",
            "photoUrl": "",
            "userId": "05588030028148674891"
          },
          "user_tz": -480
        },
        "id": "Qi7s_8ugTfgm",
        "outputId": "298cb5be-2e7b-4bf5-e63c-e87c0b5f1632"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(19617, 60, 50)"
            ]
          },
          "execution_count": 15,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "padded_sequence_data_embedded = []\n",
        "padding_vector = [0]*50 # 50 is the embedding size\n",
        "maxLen = 60\n",
        "for i in range(len(sequence_data_embedded)):\n",
        "    padded_sequence_data_embedded_for_a_user = []\n",
        "    if len(sequence_data_embedded[i]) >= maxLen:\n",
        "        padded_sequence_data_embedded_for_a_user = sequence_data_embedded[i].copy()[:maxLen]\n",
        "    else:\n",
        "        padding_size = maxLen - len(sequence_data_embedded[i])\n",
        "        padded_sequence_data_embedded_for_a_user = sequence_data_embedded[i].copy()\n",
        "        for n in range(padding_size):\n",
        "            padded_sequence_data_embedded_for_a_user.append(padding_vector)\n",
        "    padded_sequence_data_embedded.append(padded_sequence_data_embedded_for_a_user)\n",
        "len(padded_sequence_data_embedded), len(padded_sequence_data_embedded[0]), len(padded_sequence_data_embedded[0][0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "GAL76cBWTfgo"
      },
      "source": [
        "## Pad Stay Time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "colab_type": "code",
        "executionInfo": {
          "elapsed": 463,
          "status": "ok",
          "timestamp": 1590034018330,
          "user": {
            "displayName": "Hanyu Wu",
            "photoUrl": "",
            "userId": "05588030028148674891"
          },
          "user_tz": -480
        },
        "id": "HSQd52tRTfgp",
        "outputId": "5e58bb25-106d-447d-8a7b-92569eac8765"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(19617, 60)"
            ]
          },
          "execution_count": 16,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "padded_sequence_stay_time = []\n",
        "padding_vector = 0 # 50 is the embedding size\n",
        "for i in range(len(sequence_stay_time)):\n",
        "    padded_sequence_data_embedded_for_a_user = []\n",
        "    if len(sequence_stay_time[i]) >= maxLen:\n",
        "        padded_sequence_data_embedded_for_a_user = sequence_stay_time[i].copy()[:maxLen]\n",
        "    else:\n",
        "        padding_size = maxLen - len(sequence_stay_time[i])\n",
        "        padded_sequence_data_embedded_for_a_user = sequence_stay_time[i].copy()\n",
        "        for n in range(padding_size):\n",
        "            padded_sequence_data_embedded_for_a_user.append(padding_vector)\n",
        "    padded_sequence_stay_time.append(padded_sequence_data_embedded_for_a_user)\n",
        "len(padded_sequence_stay_time), len(padded_sequence_stay_time[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-04-28T03:36:39.548614Z",
          "start_time": "2020-04-28T03:36:39.542630Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "colab_type": "code",
        "executionInfo": {
          "elapsed": 383,
          "status": "ok",
          "timestamp": 1590034073169,
          "user": {
            "displayName": "Hanyu Wu",
            "photoUrl": "",
            "userId": "05588030028148674891"
          },
          "user_tz": -480
        },
        "id": "f-CbmkaFTfgr",
        "outputId": "2f57c91f-93bf-4edf-cfb3-5b5ec444f93d",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "15\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[[2.320916049678769,\n",
              "  0.8082599876604498,\n",
              "  1.6397731122301733,\n",
              "  1.4678743481123135,\n",
              "  1.6867692553704239,\n",
              "  1.7967470107390942,\n",
              "  1.660701206371642,\n",
              "  2.273259263612217,\n",
              "  2.595180077306471,\n",
              "  0.9439058989071285,\n",
              "  0.8666802313208206,\n",
              "  1.3724489542978375,\n",
              "  1.0511712140679732,\n",
              "  1.4156104154539437,\n",
              "  1.7112722183153684,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0],\n",
              " [2.320916049678769,\n",
              "  0.8082599876604498,\n",
              "  1.6397731122301733,\n",
              "  1.4678743481123135,\n",
              "  1.6867692553704239,\n",
              "  1.7967470107390942,\n",
              "  1.660701206371642,\n",
              "  2.273259263612217,\n",
              "  2.595180077306471,\n",
              "  0.9439058989071285,\n",
              "  0.8666802313208206,\n",
              "  1.3724489542978375,\n",
              "  1.0511712140679732,\n",
              "  1.4156104154539437,\n",
              "  1.7112722183153684]]"
            ]
          },
          "execution_count": 19,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# check if the len has been padded to maxLen\n",
        "print(len(sequence_stay_time[0])) \n",
        "# print(\"the shape of padded_sequence_data_embedded is {0} where {1} is the max len we set\".format(padded_sequence_data_embedded.shape, len(padded_sequence_data_embedded[0])))\n",
        "[padded_sequence_stay_time[0], sequence_stay_time[0]]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "rib7s5HlDzhR"
      },
      "source": [
        "## Save the Processed Data in Json Format"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-04-28T03:46:16.347578Z",
          "start_time": "2020-04-28T03:46:16.292725Z"
        },
        "colab": {},
        "colab_type": "code",
        "id": "urGe0Bj9DzhS"
      },
      "outputs": [],
      "source": [
        "driver_columns=['new_client', '1', '2', '3', '4', '5', '6', '7', '1_time', '2_time','3_time', '4_time', '5_time', '6_time']\n",
        "features_sequential={} ## sequential data\n",
        "features_nonsequential={} ## non sequential features -- user type, application time\n",
        "features_sequential_embedded={} ## embedded sequential data\n",
        "label={}\n",
        "# for i in range(len(keys)):\n",
        "#     uid=keys[i]\n",
        "#     driver_data=driver[driver[\"index\"]==uid]\n",
        "#     feature_nonsequential=list(driver_data[driver_columns].values[0].astype(\"float\"))\n",
        "#     features_sequential[uid]=padded_sequence_data[i]\n",
        "#     features_nonsequential[uid]=feature_nonsequential\n",
        "#     features_sequential_embedded[uid]=padded_sequence_data_embedded[i]\n",
        "#     label[uid]=driver_data[\"label\"].values[0]\n",
        "#     if i%1000==0:\n",
        "#         print(i,\"/\", len(keys))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "J6AqZhHmTfgy"
      },
      "outputs": [],
      "source": [
        "# driver[[\"index\", \"label\"]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-04-28T04:27:07.124321Z",
          "start_time": "2020-04-28T04:27:07.120321Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "colab_type": "code",
        "executionInfo": {
          "elapsed": 424,
          "status": "ok",
          "timestamp": 1590034560665,
          "user": {
            "displayName": "Hanyu Wu",
            "photoUrl": "",
            "userId": "05588030028148674891"
          },
          "user_tz": -480
        },
        "id": "qnLTJTsfTfg0",
        "outputId": "b3a0a584-77c8-4cf8-87cb-081893d7c9af"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "50"
            ]
          },
          "execution_count": 30,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(padded_sequence_data_embedded[0][0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-04-28T04:32:48.882930Z",
          "start_time": "2020-04-28T04:32:33.911483Z"
        },
        "colab": {},
        "colab_type": "code",
        "id": "UZJUIPphTfg2"
      },
      "outputs": [],
      "source": [
        "# len(features_nonsequential[\"56f889ee11df4a72955147cb2f29a638|1509322980000\"])\n",
        "# features_sequential_embedded = dict(zip(keys, padded_sequence_data_embedded))\n",
        "# write embedding sequence into pickle file\n",
        "with open(data_dir+'embedding_sequence.p', \"wb\") as fp:  # Pickling\n",
        "    pickle.dump(padded_sequence_data_embedded, fp)\n",
        "with open(data_dir+'stay_time_sequence.p', \"wb\") as fp:  # Pickling\n",
        "    pickle.dump(padded_sequence_stay_time, fp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-04-28T04:23:28.977069Z",
          "start_time": "2020-04-28T04:08:12.908Z"
        },
        "colab": {},
        "colab_type": "code",
        "id": "651A30YPDzhX"
      },
      "outputs": [],
      "source": [
        "class NpEncoder(json.JSONEncoder):\n",
        "    def default(self, obj):\n",
        "        if isinstance(obj, np.integer):\n",
        "            return int(obj)\n",
        "        elif isinstance(obj, np.floating):\n",
        "            return float(obj)\n",
        "        elif isinstance(obj, np.ndarray):\n",
        "            return obj.tolist()\n",
        "        else:\n",
        "            return super(NpEncoder, self).default(obj)\n",
        "\n",
        "\n",
        "        \n",
        "# with open(data_dir+'features_sequential_embedded.json', 'w') as f: # LSTM input with word2vec embedded \n",
        "#     json.dump(features_sequential_embedded, f, cls=NpEncoder)\n",
        "# print(\"Done saving padded_sequential_features\")\n",
        "\n",
        "\n",
        "# with open(data_dir+'padded_sequential_features.json', 'w') as f:\n",
        "#     json.dump(features_sequential, f, cls=NpEncoder)\n",
        "# print(\"Done saving padded_sequential_features\")\n",
        "\n",
        "# with open(data_dir+'non_sequential_features.json', 'w') as f:\n",
        "#     json.dump(features_nonsequential, f, cls=NpEncoder)\n",
        "# print(\"Done saving features_nonsequential\")\n",
        "\n",
        "# with open(data_dir+'label.json', 'w') as f:\n",
        "#     json.dump(label, f, cls=NpEncoder)\n",
        "# print(\"Done saving label.json\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "rhLzwrYcDzhZ"
      },
      "source": [
        "# Generate Markov Transition Field along features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-04-28T03:36:09.578260Z",
          "start_time": "2020-04-28T03:30:36.563Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "colab_type": "code",
        "executionInfo": {
          "elapsed": 341,
          "status": "error",
          "timestamp": 1590034678414,
          "user": {
            "displayName": "Hanyu Wu",
            "photoUrl": "",
            "userId": "05588030028148674891"
          },
          "user_tz": -480
        },
        "id": "aCWJLn0mDzhj",
        "outputId": "4e98a8aa-11ee-4438-e283-10fe7fba96c4"
      },
      "outputs": [],
      "source": [
        "# with open(data_dir+'padded_sequential_features_3.json') as f:\n",
        "#     sequential_features = json.load(f)\n",
        "sequential_features = features_sequential\n",
        "feature1 = np.asarray([_ for _ in sequential_features.values()])\n",
        "len(feature1[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "YsVGBvUkDzhl"
      },
      "source": [
        "- To Transform continous time features into categorical features we need to cut them into bins\n",
        "- We first explore the distribution of the time features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-04-28T03:36:09.578260Z",
          "start_time": "2020-04-28T03:30:36.565Z"
        },
        "colab": {},
        "colab_type": "code",
        "id": "l1fQ0tkBDzhn",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "x = feature1[:, :, 15].flatten()\n",
        "pd.DataFrame(x).describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "c2ezsn3NDzhq"
      },
      "source": [
        "- Cut stay time, lag time into 8 categories"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-04-28T03:36:09.580255Z",
          "start_time": "2020-04-28T03:30:36.567Z"
        },
        "colab": {},
        "colab_type": "code",
        "id": "6vjrljt8Dzhq"
      },
      "outputs": [],
      "source": [
        "stay_time=feature1[:,:,14].flatten()\n",
        "stay_time=pd.cut(x,8,labels=list(range(8)))\n",
        "stay_time=np.array(stay_time).reshape(-1,60)\n",
        "feature1[:,:,14]=stay_time\n",
        "\n",
        "lag_time=feature1[:,:,15].flatten()\n",
        "lag_time=pd.cut(x,8,labels=list(range(8)))\n",
        "lag_time=np.array(lag_time).reshape(-1,60)\n",
        "feature1[:,:,15]=lag_time"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "UGvRYDM2DziM"
      },
      "source": [
        "- Generate transition matrix\n",
        "- A 31 by 31 matrix \n",
        "- All features are bin and one-hot encoded into a binary vector.\n",
        "- matrix[i,j]  represents the probability that j=1 given i=1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-04-28T03:36:09.581252Z",
          "start_time": "2020-04-28T03:30:36.570Z"
        },
        "colab": {},
        "colab_type": "code",
        "id": "QjC_mVjEDziN"
      },
      "outputs": [],
      "source": [
        "from sklearn import preprocessing\n",
        "#test\n",
        "X =list(range(8))\n",
        "X=np.array(X)\n",
        "X=X[:,np.newaxis]\n",
        "enc = preprocessing.OneHotEncoder(categories='auto')\n",
        "enc.fit(X)\n",
        "onehotlabels = enc.transform(X).toarray()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-04-28T03:36:09.581252Z",
          "start_time": "2020-04-28T03:30:36.572Z"
        },
        "colab": {},
        "colab_type": "code",
        "id": "IJlPaYFXDziR",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "arr=[]\n",
        "for i in range(feature1.shape[0]):\n",
        "    seq=feature1[i]\n",
        "    seq=[i for i in seq if i[0]!=-1] \n",
        "    seq=np.array(seq)\n",
        "    #print(seq)\n",
        "    onehot_staytime=enc.transform(seq[:,14][:,np.newaxis]).A\n",
        "    onehot_lagtime=enc.transform(seq[:,15][:,np.newaxis]).A\n",
        "    #print(onehot_staytime)\n",
        "    seq=np.delete(seq, np.s_[0,14,15], 1)\n",
        "    seq=np.concatenate([seq, onehot_staytime,onehot_lagtime],axis=1)\n",
        "    matrix=np.zeros([seq.shape[1],seq.shape[1]])\n",
        "    for i in range(seq.shape[1]):\n",
        "        total=np.sum(seq[:,i])\n",
        "        if total==0:\n",
        "            continue\n",
        "        sub=seq[seq[:,i]==1]\n",
        "        for col in range(sub.shape[1]):\n",
        "            coappear=np.sum(sub[:,col])\n",
        "            matrix[i,col]=matrix[i,col]+coappear/total\n",
        "    arr.append(matrix)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "pOAatRqVDziT"
      },
      "source": [
        "- Save the matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-04-28T03:36:09.582252Z",
          "start_time": "2020-04-28T03:30:36.574Z"
        },
        "colab": {},
        "colab_type": "code",
        "id": "am7DSRnUDzih"
      },
      "outputs": [],
      "source": [
        "class NpEncoder(json.JSONEncoder):\n",
        "    def default(self, obj):\n",
        "        if isinstance(obj, np.integer):\n",
        "            return int(obj)\n",
        "        elif isinstance(obj, np.floating):\n",
        "            return float(obj)\n",
        "        elif isinstance(obj, np.ndarray):\n",
        "            return obj.tolist()\n",
        "        else:\n",
        "            return super(NpEncoder, self).default(obj)\n",
        "with open(data_dir+'featurematrix.json', 'w') as f:\n",
        "    json.dump(arr, f,cls=NpEncoder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "tLcoc_EvJOLT"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "data_processing.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    },
    "nteract": {
      "version": "0.26.0"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
